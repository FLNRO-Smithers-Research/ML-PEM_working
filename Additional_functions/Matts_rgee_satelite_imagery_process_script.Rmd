---
title: "01c_Satellite_SpatialLayer_Prep"
author: "Matt Coghill"
date: "02/05/2020"
output: html_document
---

# Matts scripting from Sechelt Project 
(https://github.com/mcoghill/Sechelt_Cultural_Plants/blob/master/01c_Satellite_SpatialLayer_Prep.Rmd)


This document is going to be used to pull in relevant satellite layers for analysis. This is heavily adapted from the Hackathon in Prince George (https://github.com/bcgov-datasci-labs/BCForestNonForestPEM/blob/master/01_Load_Sentinel.R) and from conversations I had with Tom Hengl regarding satellite imagery. I have provided functions for downloading cloud free medians of satellite bands as they span across a given time frame (ex: spring). This requires an interface to Google Earth Engine.

The first thing that will be done is load in the required packages. Included in this chunk is the Earth Engine initialization step. This is largely untested, so hopefully it works. If any issues arise, try restarting your R session and retrying this chunk before further troubleshooting. The Google Earth Engine requires that you have an active GMail account since files are intermediately saved from Earth Engine to Google Drive. It may send you down a road to set it up, and again it may require a restart of your R session in order to proceed properly (not super sure on that...). If any issues arise, contact me and I'll try to sort it out with you.

```{r Load Packages}
invisible(suppressPackageStartupMessages(
  lapply(c("raster", "RStoolbox", "terra", "sf", "googledrive", "tidyverse", 
           "rgee", "rstudioapi"), library, character.only = TRUE)))
# This script requires python to access Google Earth Engine. The code below will
# install the correct python libraries and initialize the Earth Engine
#ee_install() # Make sure to restart the R session before proceeding
ee_Initialize(drive = TRUE)
# rstudioapi::restartSession()
```

Next, load some local directories and file paths including relevant paths to shapes of the study area and a candidate raster layer for each resolution (used the DEM here but it could have been any raster layer of interest).

```{r Set Directories, message=FALSE, warning=FALSE}
# Define study area folder
AOI <- "Sechelt"
AOI_dir <- file.path(".", paste0(AOI, "_AOI"))
# Define covariate input folders
cov_dir <- file.path(AOI_dir, "1_map_inputs", "covariates")
all_dem <- list.files(cov_dir, pattern = "dem.tif$", full.names = TRUE, recursive = TRUE)
cov_res <- dirname(unlist(lapply(all_dem, function(x) {
  r <- rast(x)
  if(xres(r) >= 2) sources(r)[, "source"] else NULL })))
dem_list <- sapply(cov_res, list.files, pattern = "dem.tif", full.names = TRUE,
                   USE.NAMES = FALSE)
# Define AOI shape to use - defined by merged AOI area for largest extent
shp_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers")
shp_res <- dir(shp_dir, pattern = paste0(basename(cov_res), collapse = "$|"), 
               recursive = FALSE, full.names = TRUE)
shp_list <- sapply(shp_res, list.files, pattern = "aoi.gpkg", full.names = TRUE,
                   USE.NAMES = FALSE)
shp <- bind_rows(lapply(shp_list, st_read, quiet = TRUE)) %>% 
  summarise(do_union = TRUE) %>% 
  st_bbox() %>% 
  st_as_sfc()
# Define path for file processing (doesn't have to exist)
raw_dir <- file.path(AOI_dir, "0_raw_inputs", "satellite_layers")
```

Next, set up a function that will create the Earth Engine tasks to process cloud free Sentinel-2 bands. This took a while to figure out! The function requires 3 inputs:

1) An AOI polygon or multipolygon. This is provided as an sf object, converted to a bounding box, and then the bounding box shape is used as the Earth Engine polygon area of interest
2) A data.frame of date ranges used to limit the Earth Engine processing. This data.frame has 3 columns: an ID column, a start date column, and an end date column. I'm still thinking of ways to make that better, but for now that's how it is
3) A dsn (data source name) for where to place the downloaded/processed data.

The Earth Engine function works in the following manner:
1) Filters the sentinel-2 images taken between the specified start and end dates
2) Removes clouds from each of the images for each of the bands (bands are identified as beginning with the letter "B")
3) Takes the median value at each pixel for the band "stack"

Additionally, the true color bands are downloaded using their raw values (0-255). After processing, Google Earth Engine requires that the bands are saved to a Google Drive folder (or Google Cloud Services (GCS) repository, but that costs money). The bands for the specified date ranges are downloaded locally and then processed to produce the satellite indices. Satellite indices are saved within the specified DSN. Only indices that have enough data are kept (usually this means tossing out the EVI2 file).

This function keeps all of the bands at their native resolutions throughout and results with each satellite index at a raw resolution of 10m^2.

```{r Satellite Download}
# Function requires that rgee is working
get_satellite_indices <- function(aoi, date_ranges, dsn = NULL) {
  
  # Evaluate aoi input
  if(!inherits(aoi, c("sf", "sfc")))
    stop("'aoi' must be of class 'sf' or 'sfc'")
  
  if(!st_geometry_type(aoi, by_geometry = FALSE) %in% c("POLYGON", "MULTIPOLYGON"))
    stop("'aoi' must be an sf or sfc POLYGON or MULTIPOLYGON")
  
  # Evaluate date_ranges input
  if(ncol(date_ranges) != 3)
    stop(
      "'date_ranges' should be a data.frame object with 3 character class columns.
    \rColumn 1 should be a character value indicating the subfolder for the specified date range.
    \rColumn 2 should be a character value indicating the starting point of the date range.
    \rColumn 3 should be a character value indicating the ending point of the date range.")
  
  if(!all(apply(date_ranges, 2, is.character)))
    stop(
      "'date_ranges' should be a data.frame object with 3 character class columns.
    \rColumn 1 should be a character value indicating the subfolder for the specified date range.
    \rColumn 2 should be a character value indicating the starting point of the date range.
    \rColumn 3 should be a character value indicating the ending point of the date range.")
  
  # Evaluate dsn input
  if(is.null(dsn)) dsn <- getwd()
  if(!is.character(dsn))
    stop("'dsn' requires a valid file path as a character input")
  
  # Create directories for saving and reprojecting
  dl_dir <- file.path(dsn, "1_download")
  ind_dir <- file.path(dsn, "2_indices")
  
  dir.create(dl_dir, showWarnings = FALSE, recursive = TRUE)
  dir.create(ind_dir, showWarnings = FALSE, recursive = TRUE)
  
  # Set geometry for use in GEE (should make checks for polygon/multipolygon type)
  # Should force conversion to sf bounding box!
  # Projection doesn't matter, it is set properly in the download function
  ee_geom <- st_geometry(aoi) %>% 
    st_bbox() %>% 
    st_as_sfc() %>% 
    sf_as_ee()
  
  # Determine some important metadata RE sentinel 2 satellites
  sen <- ee$ImageCollection("COPERNICUS/S2_SR")
  bands <- grep("^B.*|^TCI.*", sen$first()$bandNames()$getInfo(), value = TRUE)
  scales <- sapply(bands, function(x) 
    sen$first()$select(x)$projection()$nominalScale()$getInfo())
  
  # Create a cloud masking function which will run in GEE
  cloud_mask <- function(image) {
    qa <- image$select("QA60")
    cloudBitMask <- bitwShiftL(1, 10)
    cirrusBitMask <- bitwShiftL(1, 11)
    mask <- qa$bitwiseAnd(cloudBitMask)$eq(0)$
      And(qa$bitwiseAnd(cirrusBitMask)$eq(0))
    image <- image$select("B.*")$updateMask(mask)$divide(10000L)
  }
  
  # Function selects the TCI images as well (easier viewing in GIS programs)
  add_tci <- function(image) {
    image$select("TCI.*")
  }
  
  # Perform filtering operations in GEE
  gee_run <- lapply(1:nrow(date_ranges), function(i) {
    dl_subdir <- file.path(dl_dir, date_ranges[i, 1])
    ind_subdir <- file.path(ind_dir, date_ranges[i, 1])
    
    dir.create(dl_subdir, showWarnings = FALSE)
    dir.create(ind_subdir, showWarnings = FALSE)
    
    dataset <- sen$
      filterDate(date_ranges[i, 2], date_ranges[i, 3])$
      filter(ee$Filter$lt("CLOUDY_PIXEL_PERCENTAGE", 20))
    
    rgb <- dataset$map(add_tci)$median()
    composite <- dataset$map(cloud_mask)$median()$addBands(rgb)
    
    message("Downloading Sentinel-2 Level-2A bands via GEE for dates between ", 
            date_ranges[i, 2], " and ", date_ranges[i, 3])
    # Composite image is made up of each sentinel 2 band. Need to extract the
    # bands and run the function to save the files to the download directory
    gee_dl <- lapply(bands, function(x) {
      ee_as_raster(
        composite$select(x), 
        region = ee_geom, 
        dsn = file.path(dl_subdir, paste0(x, ".tif")), 
        scale = scales[x], 
        lazy = TRUE, quiet = TRUE)})
    
    rast_bands <- ee_utils_future_value(gee_dl) %>% setNames(lapply(., names))
    message("Downloading finished! Producing satellite indices")
    
    # At this point, should perform calculations for satellite indices. Extract
    # the 10 and 20m raster bands only
    tci <- raster::stack(rast_bands[startsWith(names(rast_bands), "TCI")])
    bands_10 <- names(scales)[!startsWith(names(scales), "TCI") & scales == 10]
    bands_20 <- names(scales)[!startsWith(names(scales), "TCI") & scales == 20]
    bands_60 <- names(scales)[!startsWith(names(scales), "TCI") & scales == 60]
    res_10 <- raster::stack(rast_bands[bands_10]) %>% setMinMax()
    res_20 <- raster::stack(rast_bands[bands_20]) %>% setMinMax()
    
    # Perform pan sharpening on the 20m bands
    pan <- panSharpen(res_20, mean(res_10, na.rm = TRUE), method = "pca", norm = FALSE)
    
    # Stack the 10m bands and pan sharpened bands that are now 10m
    satellite_stack <- raster::stack(res_10, pan) %>% 
      setNames(gsub("_pan$", "", names(.)))
    
    # Create satellite indices in a single function
    satellite_indices <- spectralIndices(
      img = satellite_stack, 
      blue = "B2", green = "B3", red = "B4", nir = "B8", 
      redEdge1 = "B5", redEdge2 = "B6", redEdge3 = "B7", 
      swir2 = "B11", swir3 = "B12", 
      coefs = list(swir2ccc = max(0, minValue(satellite_stack$B11)), 
                   swir2coc = min(1, maxValue(satellite_stack$B11))))
    
    # Workaround for proper name setting
    ind_names <- names(satellite_indices)
    tci_names <- names(tci)
    satellite_indices <- rast(satellite_indices) %>% setNames(ind_names)
    tci <- rast(tci) %>% setNames(tci_names)
    
    # Remove layers that have missing data
    layer_check <- data.frame(freq(satellite_indices, value = NA)) %>% 
      dplyr::mutate(layer = names(satellite_indices[layer]), 
                    count = ncell(satellite_indices) - count) %>% 
      dplyr::filter(count > 0.95 * median(count))
    
    indices_flt <- subset(satellite_indices, layer_check$layer)
    f_names <- file.path(ind_subdir, paste0(names(indices_flt), ".tif"))
    
    # Write out files
    message("Cleaning Google Drive container and writing outputs")
    ee_clean_container(quiet = TRUE)
    tci <- writeRaster(tci, file.path(ind_subdir, "true_color.tif"), overwrite = TRUE)
    out <- writeRaster(indices_flt, f_names, overwrite = TRUE)
    raster::removeTmpFiles(h = 0)
    return(out)
    
  }) %>% setNames(date_ranges[, 1])
  
  return(gee_run)
}
```

Finally, we just need to run the function. The candidate AOI is buffered by 250m, the above function is run, and then each folder of satellite indices gets reprojected to match the DEM at each resolution. The result is masked to match the extent and shape of the DEM, and then each file is saved separately.

```{r Run functions}
# Create a buffered bounding box of the AOI
AOI_bbox <- st_buffer(shp, 250)
# Provide a data frame of dates to collect data between. The longer the data
# frame, the longer it will take to process and download your dataset.
seasons_df <- data.frame(
  season = c("winter", "spring", "summer", "fall", "2019"),
  start = c("2018-12-21", "2019-03-20", "2019-06-21", "2019-09-23", "2019-01-01"),
  end = c("2019-03-19", "2019-06-20", "2019-09-22", "2019-12-21", "2019-12-31"),
  stringsAsFactors = FALSE)
# Run get_satellite_indices function to download and process sentinel indices
sentinel_indices <- get_satellite_indices(
  aoi = AOI_bbox,
  date_ranges = seasons_df,
  dsn = raw_dir)
# The function above outputs a list format. Create a single SpatRaster of all
# of the satellite indices
sentinel_dirs <- list.dirs(file.path(raw_dir, "2_indices"), recursive = FALSE)
sentinel_indices <- rast(lapply(sentinel_dirs, function(x) {
  rast(grep("true_color.tif", 
            list.files(x, pattern = ".tif$", full.names = TRUE), 
            invert = TRUE, value = TRUE)) %>% 
    setNames(tolower(paste0("sentinel2_", names(.), "_", basename(x))))}))
# Remove progress bars for below reprojection
def_ops <- terra:::spatOptions()$progress
terraOptions(progress = 0)
# Using the raw satellite indices, reproject them, mask, and save them out.
# Note: This takes quite a while for 4m resolution, maybe better to do it by
# layer? Not sure, not tested.
sentinel_reproject <- lapply(dem_list, function(x) {
  out_dir <- dirname(x)
  cat("\nReprojecting satellite indices to", basename(out_dir))
  dem <- rast(x)
  out <- terra::project(sentinel_indices, dem) %>% 
    mask(dem) %>% 
    writeRaster(filename = file.path(out_dir, paste0(names(.), ".tif")),
      overwrite = TRUE)
  suppressWarnings(tmpFiles(remove = TRUE))
  return(out)
}) %>% setNames(basename(dirname(dem_list)))
# Reset progress bars
terraOptions(progress = def_ops)
```

##Water from NDWI layer
According to multiple sources, values of > 0 for the MNDWI layer indicate the presence of a water body. This process can be easily scripted to detect the location of water across a landscape and can be used to compare to that of the water layer downloaded as shapes from the bcdata package

https://agupubs.onlinelibrary.wiley.com/doi/full/10.1029/2018RG000598

https://www.researchgate.net/profile/Hanqiu_XU/publication/232724072_Modification_of_Normalized_Difference_Water_Index_NDWI_to_Enhance_Open_Water_Features_in_Remotely_Sensed_Imagery/links/5c9aee13299bf1116949a345/Modification-of-Normalized-Difference-Water-Index-NDWI-to-Enhance-Open-Water-Features-in-Remotely-Sensed-Imagery.pdf

```{r find water from MNDWI}
# Looking at all of the mndwi files produced, the best one to use is going to be
# the one from the summer time frame
mndwi <- lapply(dem_list, function(i) {
  if(file.exists(file.path(dirname(i), "sentinel2_mndwi_summer.tif"))) {
    mndwi_summer <- rast(file.path(dirname(i), "sentinel2_mndwi_summer.tif"))
    
    # Reclassify raster values
    water <- classify(mndwi_summer, 
                      matrix(c(-Inf, 0, NA, 0, Inf, 1), ncol = 3, byrow = TRUE))
    
    # Raster to sf conversion. Need to convert to sf because there is no 
    # geopackage support in terra package yet.
    water_sf <- as.polygons(water, crs = crs(water)) %>% 
      as("Spatial") %>% 
      st_as_sfc() %>% 
      st_set_crs(crs(water))
    
    st_write(
      water_sf, delete_dsn = TRUE, quiet = TRUE, 
      dsn = file.path(AOI_dir, "0_raw_inputs", "base_layers", 
                      basename(dirname(i)), "water_mndwi.gpkg"))
    return(water_sf)
  } else return(NULL)
})
```
