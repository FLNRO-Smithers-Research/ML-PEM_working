---
title: "Summary Metrics for Deception Test Case"
output: html_document
params:
  outDir: "."
  trDat: trDat
  target: target
  target2: target2
  tid: tid
  rseed: NA
  infiles: infiles
  mmu: mmu
  mname: mname
  field_transect: field_transect
  
---

The is script is set up as a one off to determine the optimum model balancing for a given data set. 
You should already have prepared your data and determined number of slices before compliling this script or the outputs will not work.  

In this script we compare the following method to get the best out of the data: 

1. raw
2.	downsample (under ratio = 0 - 100) ie. downsample_10
3.	smote (over ratio = 0 - 1), i.e. smote_0.5
4.	downsample and smote combination (combination of both under/over ratios) ie: ds_50_sm_0.3 (downsample to 50% and upsmote to 0.3)

This modelling used in the script is script is based on the sliced data approach. 

```{r setup, include=FALSE, echo = FALSE}

library(data.table)
library(scales)
library(sf)
library(ranger)
library(tidyverse)
library(fasterize)
library(stringr)
library(dplyr)
library(raster)
library(readxl)
library(foreach)
library(tidymodels)
library(themis)
library(vip)
require(stringi)
library(knitr)
library(ggplot2)
library(janitor)
require(ggthemes)
library(colorspace)
library(flextable)
#install.packages("flextable")

#install_github("bcgov/envreportutils")

#library(envreportutils)
```

We firstly set up the data directory for the given study area

```{r, eval = FALSE, echo = FALSE}

## set up file structure
AOI <- "Deception"
#AOI <- "DateCreek"
#AOI <- "BoundaryTSA"
#AOI <- "EagleHills"

AOI_dir <- file.path(".", paste0(AOI,"_AOI"))
cov_dir <- file.path(AOI_dir, "1_map_inputs", "covariates")
shapes_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers")
input_pnts_dir <- file.path(AOI_dir, "1_map_inputs", "trainingData", "att_5m")
out_dir <- file.path(AOI_dir, "3_maps_analysis","models")

# read in temp functions
source(here::here('_functions', 'model_gen_tidy.R'))
source(here::here('_functions', 'acc_metrix.R'))
source(here::here('_functions', 'balance_recipe.R'))
#source(here::here('_functions', 'balance_recipe_WHM.R'))
source(here::here('_functions', 'doc_theme_pem.R'))

# read in map and model keys
map.key  <- read.csv(file.path(AOI_dir, "_MapUnitLegend", 
                                 paste0(AOI, "_MapUnitLegend.csv")), 
                       stringsAsFactor = FALSE)

# #read in the fuzzy index
fMat <- read.csv(file.path(AOI_dir, "_MapUnitLegend", 
                                  "fuzzy_matrix.csv")) %>%
  dplyr::select(c(target, Pred, fVal))
fMat <- data.table(fMat)

#if(AOI == "BoundaryTSA"){
bec_shp <- st_read(file.path(shapes_dir, "bec.gpkg"), quiet = TRUE)
#} else {
#bec_shp <- st_read(file.path(shapes_dir, "bec_edited.gpkg"), quiet = TRUE)
#}

```

We then prepare the data for the modelling process

```{r run models, eval = FALSE, echo = FALSE}

# read in model parameters 
model_param <- file.path(AOI_dir, "_MapUnitLegend", "models.xlsx")

# set up model parameters:  
mparam <- read_xlsx(model_param, "models") %>% filter(to_run == 1)
map_res <- mparam$resolution
data_res <- paste0("att_", map_res, "m")
mname <- paste0(mparam$model_name)
mrep <- mparam$model_rep

# check which catergory of model to be produced
mtype <- case_when(
  str_detect(mname, "for_nf")  ~ "forest_non_forest",
  str_detect(mname, "nf_") ~ "non_forest",
  str_detect(mname, "fore") ~ "forest"
)

# get covariates
mcov <- read_xlsx(model_param, "covariates", skip = 2) %>%
  filter(!!sym(mparam$covariates) == 1) %>%
  dplyr::select(covariate)

# get training point sets
mtpt <- read_xlsx(model_param, "training_pts", skip = 2) %>%
  filter(!!sym(mparam$training_pts) == 1) %>%
  dplyr::select(tp_code)%>%
  pull

# get the map unit level 
mmu <- read_xlsx(model_param, "map_unit", skip = 2) %>%
   filter(!!sym(mparam$map_unit) == 1) %>%
  dplyr::select(legend_column)%>%
  pull

mmu <- case_when(
  mmu == "column_mu" ~ "MapUnit", 
  mmu == "column_ss" ~ "SiteSeries",
  mmu == "column_ass" ~ "Association",
  mmu == "column_cls" ~ "Class",
  mmu == "column_grp" ~ "Group",
  mmu == "column_typ" ~ "Type"
)
# set up outfolder: 
if(!dir.exists(file.path(out_dir, mtype))){dir.create(file.path(out_dir, mtype))} 

out_dir <- file.path(out_dir, mtype, mname, mrep) 

if(!dir.exists(file.path(out_dir))){dir.create(file.path(out_dir))} 

# filter covars
res_folder <- paste0(map_res, "m")
rast_list <- list.files(file.path(cov_dir, res_folder), pattern = ".tif$", full.names = TRUE)
rast_list <- rast_list[tolower(gsub(".tif", "", basename(rast_list))) %in% tolower(mcov$covariate)]
mcols <- gsub(".tif","", tolower(basename(rast_list)))

# read in training pt data
indata <- list.files(file.path(input_pnts_dir), paste0(mtpt,"_att.*.gpkg$"), full.names = TRUE)

tpts <- st_read(indata)
infiles <- basename(indata) 

# match to the key and filter for forest and non_forest points

subzones <- unique(bec_shp$BGC_LABEL)
subzones <- gsub("\\s+","",subzones)

tpts  <- tpts %>%
  cbind(st_coordinates(.)) %>%
  mutate(fnf = ifelse(grepl(paste0(subzones, collapse = "|"), mapunit1), "forest", "non_forest")) %>%
  st_join(st_transform(bec_shp[, "BGC_LABEL"], st_crs(.)), join = st_nearest_feature) %>%
  st_drop_geometry() %>% 
  rename_all(.funs = tolower) %>% 
  dplyr::select(fnf, everything()) %>%  dplyr::select(-x, -y) %>% # -bgc_cat) %>% 
  dplyr::rename(bgc_cat = bgc_label) %>% 
  rename_all(.funs = tolower) %>% 
  mutate(transect_id = gsub("\\s+","",transect_id)) %>%
  mutate(tid = gsub("\\s+","",tid)) %>%
  mutate(bgc_cat = gsub("\\s+","",bgc_cat)) %>%
  droplevels()
 
# match the column for map unit based on key 
# select the target column using the mapkey if needed: 
  map.key.sub <- map.key %>%
      dplyr::select(BaseMapUnit, !!sym(mmu)) %>%
      distinct()
  
  tpts <- tpts %>% left_join(map.key.sub, by = c("mapunit1" = "BaseMapUnit")) %>%
    left_join(map.key.sub, by = c("mapunit2" = "BaseMapUnit")) %>%
    dplyr::select(-mapunit1, -mapunit2) %>%
    dplyr::rename("mapunit1" = MapUnit.x,
                  "mapunit2" = MapUnit.y) %>%
    dplyr::select(mapunit1, mapunit2, everything())


# filter for forest or non_forest points as required
if(mtype %in% c("forest", "non_forest")) {
   tpts <- tpts %>% filter(fnf == mtype)
} 

tpts <- tpts %>%
    mutate(target = as.factor(mapunit1),
                          target2 = as.factor(mapunit2)) 

# filter columns
mpts <- tpts %>%
     dplyr::select(target, target2, transect_id, tid, id, position, slice, bgc_cat, any_of(mcols))

zones <- c(as.character(subzones))

bgc_pts_subzone <- lapply(zones, function (i){
      pts_subzone <- mpts %>%
         filter(str_detect(transect_id, as.character(paste0(i, "_")))) %>% ###changed this from target to allow inclusion of non-forest by bgc
        #filter(str_detect(target, as.character(paste0(i, "_")))) %>%
        droplevels()
      
      if(nrow(pts_subzone) == 0){ pts_subzone = NULL} else {ppts_subzone = pts_subzone }
      pts_subzone
  })
  
# generate a name for list objects removing NULL values
names <- unlist(lapply(bgc_pts_subzone, is.null))
zone_names <- zones[-(which(ll <- names)) ] 
  
# remove null or missing subzones data sets 
bgc_pts_subzone =  bgc_pts_subzone[-which(sapply(bgc_pts_subzone, is.null))]
names(bgc_pts_subzone) <- zone_names


```

We then iterate through the BGC s (this is currently a manual process). This chuck also includes the parameters to set up the balancing combination. In this case we need to adjust both the downsample and smote parameters by setting to TRUE or FALSE

- raw : downsample = FALSE, smote = FALSE
- downsampling only :  downsample = TRUE, smote = FALSE
- downsample and smote :  downsample = TRUE, smote = TRUE


```{r echo = FALSE, eval = FALSE}

  # select the bgc to use 

  xx <- names(bgc_pts_subzone[2])

  inmdata = bgc_pts_subzone[[xx]]
  out_name = names(bgc_pts_subzone[xx])
  
  inmdata_all <- inmdata
  outDir = file.path(paste(out_dir, out_name, sep = "/"))
  
  if(!dir.exists(file.path(outDir))){dir.create(file.path(outDir))} 

  # adjusted this so only checking the original and not adjacent cells
  MU_count <- inmdata_all %>% 
    dplyr::filter(position == "Orig") %>%
    dplyr::count(target) %>% filter(n > 10) 
  
  # drop anything less than 10 
   trDat <- inmdata_all %>% filter(target %in% MU_count$target)%>%
       droplevels()
  


  # note changed this as addedd the adjance cells 
  trDat_all <- trDat[complete.cases(trDat[ , 8:length(trDat)]),]
  
  # #might want to change this to just keep orig cells
  # trDat_slices <- trDat %>%
  #   group_by(slice) %>%
  #   dplyr::summarise(n.transect = length(unique(transect_id)),
  #                    n.sites = length(unique(tid))) %>%
  #   pivot_longer(cols = c("n.transect", "n.sites"), names_to = "type", values_to = "number")
  # 
  # ggplot(trDat_slices, aes(slice, number, fill = type))+
  #   geom_bar(stat = "identity", position = "dodge")+
  #   theme(axis.text.x = element_text(angle = 90))+
  #   theme_pem() +
  #   scale_fill_discrete_sequential(palette = "Light Grays")
  # 
  
  
  
# create a subset of data by removing any variables not in model (required for model to    run without error) 
  
source(here::here('_functions', 'balance_recipe.R'))
  
  trDat <- trDat_all %>% #dplyr::filter(!slice %in% c(2, 3, 4, 5)) %>% 
      mutate(slice = as.factor(slice))#,

   balance_optimisation_raw(trDat)
  
  #ds_iterations <- c(50) # 60, 70, 80, 90, 100)#10, 20, 30, 40,
  #smote_iterations <- c(0.5) # , 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)

  balance_optimisation_raw(trDat)

    balance_optimisation2(trDat)
    balance_optimisation_raw(trDat)

  


    trDat2 <- trDat_all %>%
      dplyr::select(-c( bgc_cat)) %>%
      mutate(slice = as.factor(slice))#,
             #tid = factor(tid),
             #transect_id = factor(transect_id)) %>% droplevels()

    # set up the parameters for balancing and run function to complete all model options 
    
    # ds_iterations <- c(15, 20, 30, 40, 50, 60, 70, 80, 90, 100)
    # smote_iterations <- c(0.1,0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)
      ds_iterations <- c(15, 20, 30, 40, 50)#, 60, 70, 80, 90, 100)
    smote_iterations <- c(0.2, 0.3, 0.4, 0.5, 0.6)#0.1,, 0.7, 0.8, 0.9
    # downsample
    #balance_optimisation(trDat , downsample = TRUE, smote = FALSE,  ds_iterations = ds_iterations)
    
    # raw 
    balance_optimisation( trDat2 , downsample = FALSE, smote = FALSE)
    
  # smote
    #balance_optimisation( trDat , downsample = FALSE, smote = TRUE)#,
            # smote_iterations = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9)) 
   
  # downsample & smote
    #trDat2 <- trDat #%>% dplyr::select(-transect_id)
    #balance_optimisation(trDat , downsample = TRUE, smote = TRUE)

                          # smote_iterations = c(0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9),
                          # ds_iterations = c(10, 20, 30, 40, 50, 60, 70, 80, 90, 100))
                        #  smote_iterations = c(0.3))
    
### note if you get this erro - adjust the combincation of smoting by removing the most severe (0.1, 0.2 etc)#
    
#    Error in { : 
#  task 1 failed - "Can't combine `..1$tid` <factor<f1a90>> and `..2$tid` <logical>."
#
    
        
```

Once all the models have been run we need to assess the optimised balancing option for the given data set. THis portion can be run using the knitr function to produce a report which highlights the best option for optimisation per variant. 

# 1) Optimizing for MAP - UNIT Accuracy 


```{r consolidate acc outputs and graph, echo = FALSE, fig.width=8, fig.height=8}

# consolidate outputs for each balancing method
      
 #out_dir
out_dir =  "Deception_AOI/3_maps_analysis/models/forest/fore_mu_bgc/87"
      
data_list <- list.files(file.path(out_dir), full.names = TRUE, pattern = "acc_", recursive = TRUE)

aresults <- foreach(k = data_list) %do% {
     #k = levels(slices)[5]
    print(k)
    temp <- read.csv(k)
    temp <- temp %>% dplyr::mutate(filename = paste(basename(k)))
    temp
}


acc_total <- as.data.frame(rbindlist(aresults, fill = TRUE)) %>%
  rowwise() %>%
  mutate(bgc = unlist(strsplit(target, "_"))[1])%>%
  ungroup()


# calculate predicted vs obs pc for balancing types 

multi_plot <- function(plotdata, filename){
#  svg_px(paste0(filename, ".svg"), width = 400, height = 300)
#  plot(plotdata)
#  dev.off()
  png_retina(paste0(filename, ".png"), width = 700, height = 700,
             units = "px", type = "cairo-png", antialias = "default")
  plot(plotdata)
  dev.off()
}


# PART 1: Generate Aspatial best optimisation for Unweighted results
# 
# # negative number = under predict and positive = over predicted)
# 
# df_all <- acc_total %>%
#   group_by(target, balance, bgc) %>%
#   dplyr::select(target, balance, bgc, trans.tot, pred.tot, trans.sum) %>%
#   summarise(across(where(is.numeric), sum)) %>%
#   rowwise()%>%
#   mutate(pred.ratio = pred.tot - trans.tot,
#          pred.obs.pc = (pred.ratio/trans.tot) * 100) %>%
#   mutate(pred.obs.pc = ifelse(pred.tot == 0, -100, pred.obs.pc),
#          pred.obs.type = ifelse(pred.obs.pc <0,"under predict", "over predict"),
#          pred.obs.total = ifelse(pred.obs.pc <0, pred.obs.pc*-1, pred.obs.pc)) %>%
#    ungroup()
# 
# 
# df_bgc <- unique(df_all$bgc)
# 
# for (bgcoi in df_bgc){
#    #bgcoi = df_bgc[4]
#    print(bgcoi)
#   
#       outDir <- file.path(out_dir, bgcoi)
#       
#       df <- df_all %>% 
#         dplyr::filter(bgc == bgcoi) %>%
#         dplyr::select(-bgc)
# 
#       df  <- df  %>%
#         mutate(bal_type = case_when(
#            str_detect(balance, "ds_") ~ "downsample",
#            str_detect(balance, "smote_") ~ "smote",
#            balance == "raw"~ "raw"))
#        
#       df <- df %>% 
#          rowwise() %>%
#          mutate(bal_type = ifelse(str_detect(balance, "sm_"), "ds_sm", bal_type))
#       
#       
#       downsample <- df %>% filter(bal_type %in% c("downsample", "raw"))
#       smote <- df %>% filter(bal_type %in% c("smote", "raw"))
#       ds_sm <- df %>% filter(bal_type %in% c("ds_sm", "raw"))
#     
#       
#       # Plot the top 20 iterations: 
#       
#       df_total <- df %>%
#         group_by(balance, bal_type) %>%
#         summarise(mu_devation = sum(pred.obs.total),
#                   mu_var = var(pred.obs.total),
#                   mu_mean = mean(pred.obs.total),
#                   mu_sd = sd(pred.obs.total))
#       
#       df_raw <- df_total %>% filter(balance == "raw")
#       
#       df_total_order <- df_total %>% arrange(mu_devation) 
#       #print(bgcoi)
#       #print(df_total_order)  
#       
#       df_total_order <- df_total_order[1:16,]
#       df_total_order <- df_total_order %>%
#         bind_rows(df_raw)
#       
#       df_total_order_table <- df_total_order %>%
#         mutate(across(where(is.numeric), round)) %>%
#         dplyr::select(-balance)
#       
# 
#       # plot the top 20options: 
#       
#       ds_data <- df %>%
#          filter(balance == "raw" | balance %in%  df_total_order$balance)
#        
#       ds_plot <- ggplot( ds_data , aes(x=target, y=pred.obs.pc)) +
#           geom_bar(stat='identity',  aes(fill = pred.obs.type), width=.5) +
#           coord_flip(ylim =c(-100, 110)) +
#           labs(title = paste0("Top ranked balancing deviation plot :", bgcoi),
#                subtitle = "mean deviation (blue), standard deviation (black)") +
#           facet_wrap(~ balance)
#       ds_plot
#       
#       text_ht <- length(unique(ds_data$target))
#       
#       dat_text <- df_total_order
#       dat_text$label <- sprintf(
#         "%s, %s",
#        round(dat_text$mu_mean,2),
#        str_extract(dat_text$balance,"^.{0}")
#       )
#       
#       dat_text$label2 <- sprintf(
#         "%s, %s",
#        round(dat_text$mu_sd,2),
#        str_extract(dat_text$balance,"^.{0}")
#       )
# 
#       ds_plot <- ds_plot +
#         geom_text(data = dat_text,
#                   size = 3,
#                   mapping = aes(x = text_ht , y = 90, label = label),
#                   colour = "blue"
#         ) + 
#         geom_text(data = dat_text,
#                   size = 3,
#                   mapping = aes(x = text_ht -1 , y = 90, label = label2),
#                   colour = "black"
#         ) 
#       
# 
#       multi_plot(ds_plot, file.path(outDir,"balance_optimise_plot_aspat"))
#       write.csv(df_total, file.path(outDir, "Balancing_summary_aspat.csv"))
# 
# }


## PART 2:  REPEAT THIS FOR THE SPATIALLY EXPLICIT DATA 

df_all_sp <- acc_total %>%
  group_by(target, balance, bgc) %>%
  dplyr::select(target, balance, bgc, trans.tot, spat_p_correct, trans.sum) %>%
  summarise(across(where(is.numeric), sum)) %>%
  rowwise() %>%
  mutate(pred.ratio = spat_p_correct - trans.tot,
         pred.obs.pc = (pred.ratio/trans.tot) * 100) %>%
  mutate(pred.obs.pc = ifelse(spat_p_correct == 0, -100, pred.obs.pc),
         pred.obs.type = ifelse(pred.obs.pc <0,"under predict", "over predict"),
         pred.obs.total = ifelse(pred.obs.pc <0, pred.obs.pc*-1, pred.obs.pc)) %>%
        ungroup()


df_bgc <- unique(df_all_sp$bgc)

for (bgcoi in df_bgc){
   bgcoi = df_bgc[2]
   print(bgcoi)
  
      outDir <- file.path(out_dir, bgcoi)
      
      df <- df_all_sp %>% 
        dplyr::filter(bgc == bgcoi) %>%
        dplyr::select(-bgc)

      # df  <- df  %>%
      #   mutate(bal_type = case_when(
      #      str_detect(balance, "ds_") ~ "downsample",
      #      str_detect(balance, "smote_") ~ "smote",
      #      balance == "raw"~ "raw"))
      #  
      # df <- df %>% 
      #    rowwise() %>%
      #    mutate(bal_type = ifelse(str_detect(balance, "sm_"), "ds_sm", bal_type))
      # 
      # 
      # downsample <- df %>% filter(bal_type %in% c("downsample", "raw"))
      # smote <- df %>% filter(bal_type %in% c("smote", "raw"))
      # ds_sm <- df %>% filter(bal_type %in% c("ds_sm", "raw"))
    
      
      # Plot the top 20 iterations: 
      
      df_total <- df %>%
        group_by(balance) %>%
        summarise(mu_devation = sum(pred.obs.total),
                  mu_var = var(pred.obs.total),
                  mu_mean = mean(pred.obs.total),
                  mu_sd = sd(pred.obs.total))
      
      df_raw <- df_total %>% filter(balance == "raw")
      
      df_total_order <- df_total %>% arrange(mu_devation) 
      #print(bgcoi)
      #print(df_total_order)  
      
      df_total_order <- df_total_order[1:16,]
      df_total_order <- df_total_order %>%
        bind_rows(df_raw)
      
      df_total_order_table <- df_total_order %>%
        mutate(across(where(is.numeric), round)) %>%
        dplyr::select(-balance)
      

      # plot the top 20options: 
      
      ds_data <- df %>%
         filter(balance == "raw" | balance %in%  df_total_order$balance)
       
      ds_plot <- ggplot( ds_data , aes(x=target, y=pred.obs.pc)) +
          geom_bar(stat='identity',  aes(fill = pred.obs.type), width=.5) +
          coord_flip(ylim =c(-100, 110)) +
          labs(title = paste0("Top ranked balancing deviation plot :", bgcoi),
               subtitle = "mean deviation (blue), standard deviation (black)") +
          facet_wrap(~ balance)
      ds_plot
      
      text_ht <- length(unique(ds_data$target))
      
      dat_text <- df_total_order
      dat_text$label <- sprintf(
        "%s, %s",
       round(dat_text$mu_mean,2),
       str_extract(dat_text$balance,"^.{0}")
      )
      
      dat_text$label2 <- sprintf(
        "%s, %s",
       round(dat_text$mu_sd,2),
       str_extract(dat_text$balance,"^.{0}")
      )

      ds_plot <- ds_plot +
        geom_text(data = dat_text,
                  size = 3,
                  mapping = aes(x = text_ht , y = 90, label = label),
                  colour = "blue"
        ) + 
        geom_text(data = dat_text,
                  size = 3,
                  mapping = aes(x = text_ht -1 , y = 90, label = label2),
                  colour = "black"
        ) 
      

      multi_plot(ds_plot, file.path(outDir,"balance_optimise_plot_spat"))
      write.csv(df_total, file.path(outDir, "Balancing_summary_spat.csv"))

}

# looking at the results the best models ; 

## MAP UNIT ACCURACY 

## ESSFmc 
  # aspat : ds_40_sm_0.7, ds_40_sm_0.8, ds_40_sm_0.6
  # spat  : ds_15_sm_0.2, ds_15_sm_0.4, ds_15_sm_0.3


## SBSmc2
  # aspat: ds_30_sm_0.5, ds_30_sm_0.4, ds_30_sm_0.3
  # spat : ds_15_sm_0.5, ds_30_sm_0.1, ds_15_sm_0.2


## ESSFmcw
  # aspat : ds_20_sm_0.8	, ds_20_sm_0.9	smote_0.9	smote
  # spat : ds_15_sm_0.8,  ds_15_sm_0.9, ds_40_sm_0.8,


# plot the range of values for map unit spatial optimised 

for (bgcoi in df_bgc){
  
  # bgcoi = df_bgc[2]
   print(bgcoi)
  
      outDir <- file.path(out_dir, bgcoi)
      
      df <- df_all_sp %>% 
        dplyr::filter(bgc == bgcoi) %>%
        dplyr::select(-bgc) %>%
        filter(!is.na(balance))

      df_total <- df %>%
        group_by(balance) %>%
        summarise(mu_devation = sum(pred.obs.total),
                  mu_var = var(pred.obs.total),
                  mu_mean = mean(pred.obs.total),
                  mu_sd = sd(pred.obs.total))
      
      df_total_order <- df_total %>% arrange(mu_devation) 
     
      # plot for map unit deviation 
      pp <- ggplot(data = df_total_order, aes(y = mu_mean, x = balance, colour = balance)) + 
        geom_point(stat = "identity", size = 3) + 
        theme(legend.position="none") + 
        ylab("map unit deviation mean") +
        xlab("balance type") +
        ggtitle(paste0(bgcoi, " map unit spatial accuracy"))+
        theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
      
      # plot for the map unit deviation vs overall spatial accuracy 
       bsRes <- acc_total %>%
           mutate(across(where(is.numeric), ~ replace_na(.,0))) %>%
           filter(bgc == bgcoi, 
                  acc_type == "test_estimate") %>%
           dplyr::select(-acc_type)
       
       bsRes_all <- bsRes %>% 
         group_by(slice, balance) %>%
         dplyr::select(c(balance, slice, spat_p_meanacc)) %>%
         distinct()%>%
         group_by(balance)%>%
         summarise(across(.cols = c(spat_p_meanacc), mean, n = n()))
      
      bsRes_all <- bsRes_all %>%
        left_join(df_total_order)
       
      
      po_lable_unweighted <- ggplot(bsRes_all, aes( x = spat_p_meanacc , y = mu_mean, colour = balance)) + #, shape = balance)) + 
         #geom_point(stat = "identity", size = 3) +
         geom_jitter(stat = "identity", size = 3, width = 0.001)+
         geom_text(aes(label = balance), hjust = 0.5,  vjust = -1)+
      #   ylim(0,1000) + 
        xlab("Spatial mean site accuracy") + 
        ylab("Map unit deviation") +
          ggtitle(paste0("Unweighted (Map Unit) predicted spatial deviation vs Spatial unweighted accuracy: ", bgcoi))+
       theme(legend.position="none") 
      
        po_unweighted <- ggplot(bsRes_all, aes( x = spat_p_meanacc , y = mu_mean, colour = balance)) + #, shape = balance)) + 
        # geom_point(stat = "identity", size = 3) +
         geom_jitter(stat = "identity", size = 3, width = 0.001)+

        xlab("Spatial mean site accuracy") + 
        ylab("Map unit deviation") +
          ggtitle(paste0("Unweighted (Map Unit) predicted spatial deviation vs Spatial unweighted accuracy: ", bgcoi))+
       theme(legend.position="none") 
      
        
    multi_plot(po_unweighted, file.path(outDir,"weighted_optimise_plot_spat"))
      
         
} # end of bgc loop

```

Now we can plot histogram of optimum smoting 

```{r}
# Generate models using the  optimised data set values. note you need to run blocks above to continue with the coding.

# Essfmc

  xx <- names(bgc_pts_subzone[1])

  inmdata_all = bgc_pts_subzone[[xx]]
  out_name = names(bgc_pts_subzone[xx])
  
  outDir = file.path(paste(out_dir, out_name, sep = "/"))

  MU_count <- inmdata_all %>% dplyr::count(target) %>% filter(n > 10) 
  inmdata_all <- inmdata_all %>% filter(target %in% MU_count$target)%>%
       droplevels()
  
  trDat <- inmdata_all 
  
  # Review data: Run the model 
  
  table(trDat[, "target"])
  essfmcw_raw <- ggplot(trDat, aes(target)) +
      geom_bar() + 
      theme(axis.text.x = element_text(angle = 90))

  # run the optimal component and output figure 
  
  trDat_bal  <- trDat %>%
        dplyr::select(-slice, -target2, -transect_id, -bgc_cat,-tid) %>%
        droplevels()
   
  
   null_recipe <- 
          recipe(target ~ ., data = trDat_bal) %>%
          step_downsample(target, under_ratio = 15) %>%
          step_smote(target, over_ratio = 0.8 , neighbors = 2) %>%
          prep() %>%
          juice()
  
    essfmcw_bal <- ggplot( null_recipe , aes(target)) +
        geom_bar() + 
        theme(axis.text.x = element_text(angle = 90))
  
## SBSmc2

    
  xx <- names(bgc_pts_subzone[2])

  inmdata_all = bgc_pts_subzone[[xx]]
  out_name = names(bgc_pts_subzone[xx])
  
  outDir = file.path(paste(out_dir, out_name, sep = "/"))

  MU_count <- inmdata_all %>% dplyr::count(target) %>% filter(n > 10) 
  inmdata_all <- inmdata_all %>% filter(target %in% MU_count$target)%>%
       droplevels()
  
  trDat <- inmdata_all 
  
  # Review data: Run the model 
  
  table(trDat[, "target"])
  SBSmc_raw <- ggplot(trDat, aes(target)) +
      geom_bar() + 
      theme(axis.text.x = element_text(angle = 90))

  # run the optimal component and output figure 
  trDat_bal  <- trDat %>%
        dplyr::select(-slice, -target2, -transect_id, -bgc_cat,-tid) %>%
        droplevels()
   
  
   null_recipe <- 
          recipe(target ~ ., data = trDat_bal) %>%
          step_downsample(target, under_ratio = 15) %>%
          step_smote(target, over_ratio = 0.5 , neighbors = 2) %>%
          prep() %>%
          juice()

    sbsmc_bal <- ggplot( null_recipe , aes(target)) +
        geom_bar() + 
        theme(axis.text.x = element_text(angle = 90))
  

###  ESSFmcw
    
  xx <- names(bgc_pts_subzone[1])

  inmdata_all = bgc_pts_subzone[[xx]]
  out_name = names(bgc_pts_subzone[xx])
  
  outDir = file.path(paste(out_dir, out_name, sep = "/"))

  MU_count <- inmdata_all %>% dplyr::count(target) %>% filter(n > 10) 
  inmdata_all <- inmdata_all %>% filter(target %in% MU_count$target)%>%
       droplevels()
  
  trDat <- inmdata_all 
  
  # Review data: Run the model 
  
  table(trDat[, "target"])
  essfmc_raw <- ggplot(trDat, aes(target)) +
      geom_bar() + 
      theme(axis.text.x = element_text(angle = 90))

  # run the optimal component and output figure 
  trDat_bal  <- trDat %>%
        dplyr::select(-slice, -target2, -transect_id, -bgc_cat,-tid) %>%
        droplevels()
   
  
   null_recipe <- 
          recipe(target ~ ., data = trDat_bal) %>%
          step_downsample(target, under_ratio = 15) %>%
          step_smote(target, over_ratio = 0.2 , neighbors = 2) %>%
          prep() %>%
          juice()
  
    essfmc_bal <- ggplot( null_recipe , aes(target)) +
        geom_bar() + 
        theme(axis.text.x = element_text(angle = 90))
  
    
    
mumap <- grid.arrange(essfmc_raw,   essfmc_bal, SBSmc_raw , sbsmc_bal ,essfmcw_raw, essfmcw_bal, nrow = 3)

    
```



### PART 2: Optimising for Overall accuracy metrics 

Above we optimise for map unit accuracy, howver we want to also investigate the impact of optimising for overall accuracy. 

In this step we can use the curve plotting the overall accuracy vs 


```{r}

# consolidate outputs for each balancing method
      
 #out_dir
out_dir =  "Deception_AOI/3_maps_analysis/models/forest/fore_mu_bgc/87"
      
data_list <- list.files(file.path(out_dir), full.names = TRUE, pattern = "acc_", recursive = TRUE)

aresults <- foreach(k = data_list) %do% {
     #k = levels(slices)[5]
    print(k)
    temp <- read.csv(k)
    temp <- temp %>% dplyr::mutate(filename = paste(basename(k)))
    temp
}

acc_total <- as.data.frame(rbindlist(aresults, fill = TRUE)) %>%
  rowwise() %>%
  mutate(bgc = unlist(strsplit(target, "_"))[1])%>%
  ungroup()


# plot the overall aspatial accuracy measure with the overall divergence value

 bsRes <- acc_total %>%
     mutate(across(where(is.numeric), ~ replace_na(.,0)))
 
 bsRes_all <- bsRes %>%
   dplyr::select(bgc, balance, aspat_p_overall, aspat_p_meanacc,
                 spat_p_overall, spat_p_meanacc, slice) %>%
   distinct() %>%
   group_by(balance, bgc)
   
  bsRes_all_mean <- bsRes_all %>%
    summarise(across(.cols = c(aspat_p_overall, aspat_p_meanacc, spat_p_overall,   spat_p_meanacc), list(mean = mean, sd = sd), n = n())) %>%
    filter(!is.na(balance))
   
aspat <- ggplot(bsRes_all_mean, aes( x = aspat_p_overall_mean , y = aspat_p_meanacc_mean, colour = balance)) +
   facet_wrap(~bgc, nrow = 3, scales = "free")+ 
   geom_point(stat = "identity", size = 3) +
    xlab("Aspatial mean site accuracy") + 
    ylab("Aspatial overall accuracy") +
    #theme(legend.position="none") +
    ggtitle("Aspatial area weighted (overall) vs unweighted (map accuracy)")

aspat 

      
po_lable <- ggplot(bsRes_all_mean, aes( y = aspat_p_overall_mean , x = balance, colour = balance)) + #, shape = balance)) + 
      facet_wrap(~bgc, nrow = 3, scales = "free_y")+ 
      geom_point(stat = "identity", size = 3) +
      #geom_text(aes(label = balance), hjust = 0.5,  vjust = -1)+
        # ylim(0,1000) + 
        xlab("Spatial mean site accuracy") + 
        ylab("Map unit deviation") +
          ggtitle(paste0("Area-weighted (Overall) aspatial accuracy: ", bgcoi))+
       theme(legend.position="none") +
  theme(axis.text.x = element_text(angle = 90))
po_lable 
      
po <- ggplot(bsRes_all, aes( x = spat_p_meanacc , y = mu_mean, colour = balance)) + #, shape = balance)) + 
        # geom_point(stat = "identity", size = 3) +
         geom_jitter(stat = "identity", size = 3, width = 0.001)+

        xlab("Spatial mean site accuracy") + 
        ylab("Map unit deviation") +
          ggtitle(paste0("Unweighted (Map Unit) predicted spatial deviation vs Spatial unweighted accuracy: ", bgcoi))+
       theme(legend.position="none") 



# spat <- ggplot(bsRes_all, aes( x = spat_p_meanacc , y = spat_p_overall, colour = balance)) +
#    facet_wrap(~bgc, nrow = 3, scales = "free")+ 
#    geom_point(stat = "identity", size = 3) +
#   xlab("Spatial mean site accuracy") + 
#   ylab("Spatial overall accuracy") +
#   theme(legend.position="none") +
#   ggtitle("Spatial area weighted vs unweighted")
# 
# spat

```

Select the top ranked models for the overall accuracy

```{r}

essfmc <- bsRes_all_mean %>% 
  dplyr::filter(bgc == "ESSFmc") %>%
  dplyr::select(c(-spat_p_overall_mean, -spat_p_meanacc_mean, -spat_p_meanacc_sd, -spat_p_overall_sd))%>%
  #mutate(all_spat = aspat_p_overall + spat_p_overall) %>%
  arrange(desc(aspat_p_overall_mean)) #%>% # 0.72 - 0.81
  #arrange(desc(spat_p_overall)) #%>%   # 0.34 - 0.45
  #arrange(desc(all_spat))


# top ranked aspat: ds_90_sm_0.9, ds_70_sm_0.9, ds_60_sm_0.9
# top ranked spat_overal = smote_0.2
  
essfmcw <- bsRes_all_mean %>% 
  dplyr::filter(bgc == "ESSFmcw") %>%
  dplyr::select(c(-spat_p_overall_mean, -spat_p_meanacc_mean, -spat_p_meanacc_sd, -spat_p_overall_sd))%>%
  arrange(desc(aspat_p_overall_mean)) #%>% #(0.79 - 0.83)
  #arrange(desc(spat_p_overall)) #%>% # 0.54 - 0.58
 # arrange(desc(all_spat))

# top ranked aspat : ds_20_sm_0.9,  ds_20_sm_0.5, smote_0.8
# Top ranked spat_data = ds_20

sbs <- bsRes_all_mean %>% 
  dplyr::filter(bgc == "SBSmc2")%>%
  dplyr::select(c(-spat_p_overall_mean, -spat_p_meanacc_mean, -spat_p_meanacc_sd, -spat_p_overall_sd))%>%
  arrange(desc(aspat_p_overall_mean))  #(0.77 - 0.87)
  #arrange(desc(spat_p_overall)) #%>% # 0.48 - 0.58
 # arrange(desc(all_spat))

# top ranked aspat :  ds_70_sm_0.3  ds_80_sm_0.2, ds_80_sm_0.4
# top ranked spat _ overall = ds_100_sm_0.1


```


Now we can plot histogram of optimum smoting for overall data 

```{r}
# you will need to run blocks above to contiue with the coding 

  xx <- names(bgc_pts_subzone[3])

  inmdata_all = bgc_pts_subzone[[xx]]
  out_name = names(bgc_pts_subzone[xx])
  
  outDir = file.path(paste(out_dir, out_name, sep = "/"))

  MU_count <- inmdata_all %>% dplyr::count(target) %>% filter(n > 10) 
  inmdata_all <- inmdata_all %>% filter(target %in% MU_count$target)%>%
       droplevels()
  
  trDat <- inmdata_all 
  
  # Review data: Run the model 
  
  table(trDat[, "target"])
  essfmcw_raw <- ggplot(trDat, aes(target)) +
      geom_bar() + 
      theme(axis.text.x = element_text(angle = 90))

  # run the optimal component and output figure 
  
    trDat_bal  <- trDat %>%
        dplyr::select(-slice, -target2, -transect_id, -bgc_cat,-tid) %>%
        droplevels()
   
  #ds_90_sm_0.9
   null_recipe <- 
          recipe(target ~ ., data = trDat_bal) %>%
          step_downsample(target, under_ratio = 20) %>%
          step_smote(target, over_ratio = 0.9 , neighbors = 2) %>%
          prep() %>%
          juice()
  
    essfmcw_bal <- ggplot( null_recipe , aes(target)) +
        geom_bar() + 
        theme(axis.text.x = element_text(angle = 90))

    
    ### SBSmc
     xx <- names(bgc_pts_subzone[2])

  inmdata_all = bgc_pts_subzone[[xx]]
  out_name = names(bgc_pts_subzone[xx])
  
  outDir = file.path(paste(out_dir, out_name, sep = "/"))

  MU_count <- inmdata_all %>% dplyr::count(target) %>% filter(n > 10) 
  inmdata_all <- inmdata_all %>% filter(target %in% MU_count$target)%>%
       droplevels()
  
  trDat <- inmdata_all 
  
  # Review data: Run the model 
  
  table(trDat[, "target"])
  SBSmc_raw <- ggplot(trDat, aes(target)) +
      geom_bar() + 
      theme(axis.text.x = element_text(angle = 90))

  # run the optimal component and output figure 
  trDat_bal  <- trDat %>%
        dplyr::select(-slice, -target2, -transect_id, -bgc_cat,-tid) %>%
        droplevels()
   
  
   null_recipe <- 
          recipe(target ~ ., data = trDat_bal) %>%
          step_downsample(target, under_ratio = 70) %>%
          step_smote(target, over_ratio = 0.3 , neighbors = 2) %>%
          prep() %>%
          juice()
 # ds_70_sm_0.3
    sbsmc_bal <- ggplot( null_recipe , aes(target)) +
        geom_bar() + 
        theme(axis.text.x = element_text(angle = 90))

    
    
    # ESSFmc
  xx <- names(bgc_pts_subzone[1])

  inmdata_all = bgc_pts_subzone[[xx]]
  out_name = names(bgc_pts_subzone[xx])
  
  outDir = file.path(paste(out_dir, out_name, sep = "/"))

  MU_count <- inmdata_all %>% dplyr::count(target) %>% filter(n > 10) 
  inmdata_all <- inmdata_all %>% filter(target %in% MU_count$target)%>%
       droplevels()
  
  trDat <- inmdata_all 
  
  # Review data: Run the model 
  
  table(trDat[, "target"])
  essfmc_raw <- ggplot(trDat, aes(target)) +
      geom_bar() + 
      theme(axis.text.x = element_text(angle = 90))

  # run the optimal component and output figure 
  trDat_bal  <- trDat %>%
        dplyr::select(-slice, -target2, -transect_id, -bgc_cat,-tid) %>%
        droplevels()
   
 # ds_90_sm_0.9,
   null_recipe <- 
          recipe(target ~ ., data = trDat_bal) %>%
           step_downsample(target, under_ratio = 90) %>%
          step_smote(target, over_ratio = 0.9 , neighbors = 2) %>%
          prep() %>%
          juice()
  
    essfmc_bal <- ggplot( null_recipe , aes(target)) +
        geom_bar() + 
        theme(axis.text.x = element_text(angle = 90))
  
grid.arrange( essfmc_raw,  essfmc_bal, SBSmc_raw , sbsmc_bal ,essfmcw_raw, essfmcw_bal, nrow = 3)

```




## Part 3 Theta weighted optimised 

```{r}

out_dir =  "Deception_AOI/3_maps_analysis/models/forest/fore_mu_bgc/87"
      
data_list <- list.files(file.path(out_dir), full.names = TRUE, pattern = "acc_", recursive = TRUE)

aresults <- foreach(k = data_list) %do% {
     #k = levels(slices)[5]
    print(k)
    temp <- read.csv(k)
    temp
}

acc_total <- as.data.frame(rbindlist(aresults, fill = TRUE)) %>%
  rowwise() %>%
  mutate(bgc = unlist(strsplit(target, "_"))[1])%>%
  ungroup()

head(acc_total)



acc_total_b <- acc_total %>% filter(bgc == "SBSmc2") %>%
  filter(!is.na(balance))
#SBSmc2") #"ESSFmcw") # 

theta_vals <- c(0.1, 0.2, 0.3, 0.4, 0.5, 0.6)


theta_vals_results <- foreach(t = theta_vals) %do% { # loop theta values 
   # t = theta_vals[1]
    print(t)
    
    data_list <- unique(acc_total_b$balance)
    
    theta_results <- foreach(k = data_list) %do% { # loop the balance values
        
        #k = unique(acc_total_b$balance)[1]
        print(k)
        temp <- acc_total_b %>%
          filter(balance == k)
        
        temp_out <- theta_accuracy(temp, theta = t)
        temp_out <- temp_out %>% ungroup() %>% 
          dplyr::select(spat_p_theta, aspat_p_theta) %>% 
          distinct() %>% 
          summarise(mutate(across(ends_with("theta"), ~ mean(.x)))) %>%
          mutate(balance = k)
    
        }
    
    theta_df <- as.data.frame(rbindlist(theta_results, fill = TRUE)) %>%
      rowwise() %>%
      mutate(theta = t)
    
}
    
 theta_df_all <- as.data.frame(rbindlist(theta_vals_results , fill = TRUE)) %>%
      rowwise() 

 
# Plot the spatial and aspatial accuracy theta. 

th_spat <- ggplot( theta_df_all, aes( y = spat_p_theta , x= balance, colour = theta)) + #, shape = balance)) + 
      #facet_wrap(~bgc, nrow = 3, scales = "free_y")+ 
      geom_point(stat = "identity", size = 3) +
      #geom_text(aes(label = balance), hjust = 0.5,  vjust = -1)+
        # ylim(0,1000) + 
        xlab("Balance") + 
        ylab("Spatial theta accuracy") +
          ggtitle(paste0("theta weighted spatial accuracy: ", bgcoi))+
       #theme(legend.position="none") #+
  theme(axis.text.x = element_text(angle = 90))
      
 th_spat
 
 
 th_aspat <- ggplot( theta_df_all, aes( y = aspat_p_theta , x= balance, colour = theta)) + #, shape = balance)) + 
      #facet_wrap(~bgc, nrow = 3, scales = "free_y")+ 
      geom_point(stat = "identity", size = 3) +
      #geom_text(aes(label = balance), hjust = 0.5,  vjust = -1)+
        # ylim(0,1000) + 
        xlab("Balance") + 
        ylab("Aspatial theta accuracy") +
          ggtitle(paste0("theta weighted aspatial accuracy: ", bgcoi))+
       #theme(legend.position="none") #+
  theme(axis.text.x = element_text(angle = 90))
      
 th_aspat
 
 
# select the top values for spat_p and aspat_p theta 
out_top <-  theta_df_all %>%
  group_by(theta) %>%
  summarise(spat_p_theta_t = max(spat_p_theta),
            aspat_p_theta_t = max(aspat_p_theta)) 



# # plot all the range of values 
# 
# out_top_bal_spat <- theta_df_all %>%
#   filter(spat_p_theta %in% out_top$spat_p_theta_t)
# 
# out_top_bal_aspat <- theta_df_all %>%
#   filter(aspat_p_theta %in% out_top$aspat_p_theta_t)
# 
# 
# #out_top <- left_join(out_top, out_top_bal)
# 
# 
# all <- bsRes_all %>%
#   filter(bgc == "SBSmc2") %>% 
#   filter(!is.na(balance))
# 
# out_top_bal_aspat <- left_join(out_top_bal_aspat, all)
# 
# 
# 
# aspat <- ggplot(all, aes( x = aspat_p_meanacc , y = aspat_p_overall, colour = balance, label = balance)) +
#   geom_text(aes(label=balance),hjust=0, vjust=0)+ 
#    geom_point(stat = "identity", size = 3) +
#   xlab("Aspatial mean site accuracy") + 
#   ylab("Aspatial overall accuracy") +
#   theme(legend.position="none") +
#   ggtitle("Aspatial area weighted vs unweighted") +
#  # geom_point(out_top_bal_aspat, aes(x = aspat_p_meanacc , y = aspat_p_overall, label = theta))+
#    geom_text(aes(label=theta),hjust=0, vjust=0)
# 
# aspat 
# 
# spat <- ggplot(all, aes( x = spat_p_meanacc , y = spat_p_overall, colour = balance,label = balance)) +
#    geom_text(aes(label=balance),hjust=0, vjust=0)+ 
#   geom_point(stat = "identity", size = 3) +
#   xlab("Spatial mean site accuracy") + 
#   ylab("Spatial overall accuracy") +
#   theme(legend.position="none") +
#   ggtitle("Spatial area weighted vs unweighted")
# 
# spat
# 



```

# explore the impact of Theta 

```{r}
# Look at the top rated models and identify theta in each of these: 

## Overall area wt (aspatial values)

#essfmcw: ds_20_sm_0.9,  ds_20_sm_0.5, smote_0.8
#sbsmc2: ds_70_sm_0.3  ds_80_sm_0.2, ds_80_sm_0.4
#essfmc: ds_90_sm_0.9, ds_70_sm_0.9, ds_60_sm_0.9

## Map Unit Unweighted (spatial values)

#essfmcw: ds_15_sm_0.8,  ds_15_sm_0.9, ds_40_sm_0.8,
#sbsmc2: ds_15_sm_0.5, ds_30_sm_0.1, ds_15_sm_0.2
#essfmc: ds_15_sm_0.2, ds_15_sm_0.4, ds_15_sm_0.3

 bsRes <- acc_total %>%
     mutate(across(where(is.numeric), ~ replace_na(.,0)))
 
 bsRes_all <- bsRes %>%
   dplyr::select(bgc, balance, aspat_p_overall, aspat_p_meanacc,
                 spat_p_overall, spat_p_meanacc, slice) %>%
   distinct() %>%
   group_by(balance, bgc)
   
  bsRes_all_mean <- bsRes_all %>%
    summarise(across(.cols = c(aspat_p_overall, aspat_p_meanacc, spat_p_overall,   spat_p_meanacc), list(mean = mean, sd = sd), n = n())) %>%
    filter(!is.na(balance))
  
  
bgcoi = "ESSFmcw"
bals <- c("ds_20_sm_0.9", "ds_15_sm_0.8")

bgc_dat <- bsRes_all_mean %>%
  filter(bgc == bgcoi ) %>%
  filter(balance %in% bals)



```





