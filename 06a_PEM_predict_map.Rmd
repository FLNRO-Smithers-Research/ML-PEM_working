---
title: "05a_PEM_predict_map"
author: "G. Perkins"
date: "06/11/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(sf)
library(dplyr)
library(readxl)
library(stringr)
library(raster)
library(stars)
#install.packages("pemgeneratr")

```

```{r set up folders, echo = FALSE}

AOI <- "Deception"
#AOI <- "EagleHills"
#AOI <- "BoundaryTSA"

#read in functions: 
source(here::here('_functions', 'predict_map_tidy.R'))

# set up file structure
AOI_dir <- file.path(".", paste0(AOI,"_AOI"))
cov_dir <- file.path(AOI_dir, "1_map_inputs", "covariates")
shapes_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers")
out_dir <- file.path(AOI_dir, "3_maps_analysis","models")

bec_shp <- st_read(file.path(shapes_dir, "bec.gpkg"), quiet = TRUE)
  
# read in map and model keys
map.key  <- read.csv(file.path(AOI_dir, "_MapUnitLegend", 
                                 paste0(AOI, "_MapUnitLegend.csv")), 
                       stringsAsFactor = FALSE)

model_param <- file.path(AOI_dir, "_MapUnitLegend", "models.xlsx")

# set up model parameters:  
mparam <- read_xlsx(model_param, "models") %>% filter(to_run == 1)
map_res <- mparam$resolution
mname <- paste0(mparam$model_name)
mrep <- mparam$model_rep

# check which catergory of model to be produced
mtype <- case_when(
  str_detect(mname, "for_nf")  ~ "forest_non_forest",
  str_detect(mname, "nf_") ~ "non_forest",
  str_detect(mname, "fore") ~ "forest"
)

# get covariates
mcov <- read_xlsx(model_param, "covariates", skip = 2) %>%
  filter(!!sym(mparam$covariates) == 1) %>%
  dplyr::select(covariate)


modeltype = "final_tmodel.rds" #for tidy model 
  ## or "model.rds" for mlr model 
#mtype = "model.rds"

```


```{r set up covariates stack }

map_res = 5
res_folder <- paste0(map_res, "m")

rast_list <- list.files(file.path(cov_dir, res_folder), pattern = ".tif$", full.names = TRUE)

# filter based on covariate for model param
rast_list <- rast_list[tolower(gsub(".tif", "", basename(rast_list))) %in% tolower(mcov$covariate)]

```


#Generate a map

```{r Generate map for foreset section}

if(str_detect(mname, "_all")){
  # run all bgc models 
  print ("producing combined map")
  
    outDir <- file.path(out_dir, "forest", mname, mrep, "all")
    outDir <- file.path(out_dir, "forest_non_forest", mname, mrep)
    
      predict_map_tidy(
        model = file.path(outDir, modeltype),
        cov = rast_list,
        tilesize = 500,
        outDir = outDir)
  
} else {

print("stitching bgc maps together")

bgcs = c("IDFdk1","IDFxh2")
#bgcs = c("SBSmc2","ESSFmc","ESSFmcw")
#bgcs = c("ICHmk1" , "IDFdm1", "ICHxw","MSdm1","ICHdw1","ESSFmh","ICHmw5")
            #  "ESSFdc1", "ESSFdc2", "MSdm1",   "IDFdh")  
#complete"ICHmk1" , "IDFdm1", 
#bgc = "SBSmc2" 
#mrep = 17

  for( bgc in bgcs) {
      
      #bgc = "IDFdk1"
    
      ## nf model 
      #mname = "nf_class"
      #outDir <- file.path(out_dir, "non_forest", mname, mrep)
  
      outDir <- file.path(out_dir, "forest", mname, mrep, bgc)
      
      predict_map_tidy(
        model = file.path(outDir, modeltype),
        cov = rast_list,
        tilesize = 500,
        outDir = outDir)
      
  } 
}



## If you get this error: 
              
#One of your rasters does not have a projection               
            
# for (i in 1:length(rast_list)){
#   
#   rasterr <- raster(rast_list[i])
#  
#   paste0(print(basename(rast_list[i])),":", print(crs(rasterr)))
#   
#   #print(crs(rasterr))
#   
# }              
#  aspect <- raster(rast_list[25])
#  aspect
#  slope <- raster(rast_list[26])
#  crs(slope)<- crs(aspect)
# # bgc <- raster(rast_list[2])
# # 
# # crs(bgc) = crs(aspect) 
# # # read in as gdal and saga (or regenerate from scratch).
# # 
# writeRaster(slope, "E:/temp/PEM_DATA/BEC_DevExchange_Work/BoundaryTSA_AOI/1_map_inputs/covariates/5m/slope.tif", overwrite = TRUE)
# 
# #E:\temp\PEM_DATA\BEC_DevExchange_Work\BoundaryTSA_AOI\1_map_inputs\covariates\5m


```



## Generate final map by joining BGC maps together

```{r}
# Assemble the BGC's maps: 

#AOI <- "Deception"
#AOI <- "BoundaryTSA"

# set up file structure
AOI_dir <- file.path(".", paste0(AOI,"_AOI"))
cov_dir <- file.path(AOI_dir, "1_map_inputs", "covariates")
shapes_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers")
out_dir <- file.path(AOI_dir, "3_maps_analysis","models")


# load bgc layer

bec_shp <- st_read(file.path(shapes_dir, "bec.gpkg"), quiet = TRUE) %>%
  mutate(BGC_LABEL = gsub(" ","",BGC_LABEL))

aoi <- st_read(file.path(shapes_dir, "AOI.gpkg"), quiet = TRUE)

# read in map and model keys
map.key  <- read.csv(file.path(AOI_dir, "_MapUnitLegend", 
                                 paste0(AOI, "_MapUnitLegend.csv")), 
                       stringsAsFactor = FALSE)


#map_dir = "D:/PEM_DATA/BEC_DevExchange_Work/Deception_AOI/3_maps_analysis/models/forest/fore_mu_bgc/67"
#map_dir = "D:/PEM_DATA/BEC_DevExchange_Work/Deception_AOI/3_maps_analysis/models/forest_non_forest/for_nfor/1"
#map_dir = "D:/PEM_DATA/BEC_DevExchange_Work/Deception_AOI/3_maps_analysis/models/forest/fore_mu_bgc/93"

#map_dir = "E:/temp/PEM_DATA/BEC_DevExchange_Work/BoundaryTSA_AOI/3_maps_analysis/models/forest/fore_mu_bgc/9"

map_dir ="D:/PEM_DATA/BEC_DevExchange_Work/EagleHills_AOI/3_maps_analysis/models/forest/fore_mu_bgc/1"


#folders <- as.list(c("ESSFmc", "ESSFmcw", "SBSmc2")) 
#folders <- as.list(c("ESSFmc","SBSmc2"))
#folders <- as.list(c("ICHmk1" , "IDFdm1", "ICHxw","MSdm1","ICHdw1","ESSFmh","ICHmw5"))
folders <- as.list(c("IDFdk1","IDFxh2"))

# step 1:  set up a key for the combined map (includes all the units)
rkey <- lapply(folders, function (f){
  
  keys <- read.csv(file.path(map_dir, f, "response_names.csv")) %>%
    mutate(model  = f)
})

rkey <- do.call("rbind", rkey)
rkey <- rkey %>% dplyr::mutate(map.response = seq(1:length(x)))


# Step 2: For each bgc, filter and mask the raster map and update key if needed

combo_map <- lapply(folders, function(f){
  
 # f <- folders[[1]]
  
  rtemp <- raster(file.path(map_dir, f, "mosaic.tif"))
  
  rtemp[is.na(rtemp[])] <- 0 
  
  # filter to only predict over bgc
  bec_filter <- bec_shp %>%
    filter(BGC_LABEL == f) %>%
    dplyr::select(BGC_LABEL) 
    
  rtemp <- raster::mask(rtemp, as(bec_filter,'Spatial'))
  
  subkey <- rkey %>% dplyr::filter(model == f) %>%
    mutate(mosaic = as.numeric(rownames(.)))

   # check if the key matches or needs reclassification 
  if (isTRUE(unique(subkey$mosaic == subkey$map.response))) {
    
    print("matching key")
  
  } else {
    
    print("updating key")
 
    m <- subkey %>%
      mutate(to = as.numeric(X), 
              from = as.numeric(X)+1) %>%
      dplyr::select(to, from, map.response) 
      
    reclm <-  as.matrix(m, ncol=3, byrow= TRUE)
    rtemp <-  reclassify(rtemp, reclm, right = FALSE)#, include.lowest=TRUE)
  
  }
  
  rtemp <- reclassify(rtemp, cbind(-Inf, 0, NA), include.lowest=TRUE)
  rtemp
  
})

# join all the maps together

if(length(folders) == 3) {
  
  all_key <- merge(combo_map[[1]], combo_map[[2]], overlap=TRUE)
  all_key <- merge(all_key, combo_map[[3]], overlap = TRUE)

} 

all_key <- merge(combo_map[[1]], combo_map[[2]], overlap=TRUE)
all_key <- merge(all_key, combo_map[[3]], overlap = TRUE)
all_key <- merge(all_key, combo_map[[4]], overlap = TRUE)
all_key <- merge(all_key, combo_map[[5]], overlap = TRUE)
all_key <- merge(all_key, combo_map[[6]], overlap = TRUE)
all_key <- merge(all_key, combo_map[[7]], overlap = TRUE)

# tidy key and output maps
rkey <- rkey %>% dplyr::select(x, model, map.response)
       
writeRaster(all_key, file.path(map_dir, "forest_combo_bgcs.tif"), overwrite = TRUE)

write.csv(rkey, file.path(map_dir, "response_combo_bcgs_key.csv"))

```









# option 2: generate a map using the mlr model map 

```{r}
# predict map using mlr model 
  
predict_map(model =  paste0(out_dir,"/", mname, "/", modeltype),
         #   "./Deception_AOI/3_maps_analysis/models/forest/fore_mu_bgc/3/fore_mu_bgc/model.rds",
                  cov = rast_list, 
                  tilesize = 500,
                  outDir = paste0(out_dir,"/", mname,"/predicted"))

  
# predict series of maps: 

bgcs <- list.files(paste0(out_dir))

for (b in bgcs) {
b = bgcs[1]
#bgc <- bgcs[2]
model_name <- file.path(out_dir, b, "model.rds")
  
predict_map(model = model_name, 
                  cov = rast_list, 
                  tilesize = 500,
                  outDir = paste0(out_dir,"/", b,"/predicted"))

}

```


# generate map for forest/non_forest split 

```{r}
# temp fix 

# read in non-forest map generated at 5m accuracy
nf_f <- file.path(out_dir, "forest_non_forest/for_nfor_all/2/for_nfor_all/predicted/")
list.files(nf_f)


# generate rasters for AOI 
nf_f_map <- terra::rast(file.path(nf_f, "response.tif"))
nf_f_key <- read.csv(file.path(nf_f, "response_names.csv"))

nf_f_key <- nf_f_key %>% mutate(x = case_when(
  x == "clearcut" ~ "forest", 
  TRUE ~ as.character(.$x)))

nf_f_key
#  X         x
# 1  clearcut
# 2    forest
# 3 nonforest
# 4     water

m <- c(1,2, 1)
rclmat <- matrix(m, ncol=3, byrow=TRUE)
forest_aoi <- terra::classify(aoi, rclmat, othersNA=TRUE, include.lowest=TRUE)

m <- c(4, 1)
rclmat <- matrix(m, ncol=2, byrow=TRUE)
water_aoi <- terra::classify(aoi, rclmat, othersNA=TRUE, include.lowest=TRUE)

m <- c(3, 1)
rclmat <- matrix(m, ncol=2, byrow=TRUE)
nf_aoi <- terra::classify(aoi, rclmat, othersNA=TRUE, include.lowest=TRUE)


##aoi_poly <- aoi %>% 
#  st_as_sf(as_points = FALSE, merge = TRUE, na.rm = TRUE, use_integer = TRUE) %>%
#  st_transform(3005) %>%
#  left_join(aoi_key, by = c("response.tif" = "X"))


```


# generate the non-forest map and join to forested map

```{r}
# inorder to generate the non -forest model and join to the forested model we need to select the model of inerest : 

# define 
#- forest / non-forest mask model
#- forested model
#- non-forest model 

AOI <- "Deception"
#AOI <- "BoundaryTSA"

# set up file structure
AOI_dir <- file.path(".", paste0(AOI,"_AOI"))
out_dir <- file.path(AOI_dir, "3_maps_analysis","models")
shapes_dir <- file.path(AOI_dir, "0_raw_inputs", "base_layers")

fnf <- file.path(out_dir, "forest_non_forest", "for_nfor", "2")
f <- file.path(out_dir, "forest", "for_mu_bgc", "76")
nf <- file.path(out_dir, "non_forest","nf_class","2")

# read in non-forest and forest split
#nff_map <- stars::read_stars(file.path(fnf, "mosaic.tif"))
nff_map  <- raster(file.path(fnf, "mosaic.tif"))
nff_key <- read.csv(file.path(fnf, "response_names.csv"))

# read in non-forest map generated at 5m accuracy
nf_map <- raster(file.path(nf, "mosaic.tif"))
nf_key <- read.csv(file.path(nf, "response_names.csv"))

# crop to AOI and write out 
#all_key <- read_stars(file.path(map_dir, "mosaic.tif"))
#all_key <- st_crop(all_key, aoi)
#stars::write_stars(all_key, file.path(map_dir, "mosaic1.tif")) #tile name
       



aoi = st_read(file.path(shapes_dir, "AOI.gpkg")) %>%
  st_transform(3005) 


# crop to AOI and write out 
all_key <- read_stars(file.path(nf, "mosaic.tif"))
all_key <- st_crop(all_key, aoi)
stars::write_stars(all_key, file.path(map_dir, "mosaic_aoi.tif")) #tile name
    

## Generate the non-forest mask 
#f_mask <- nff_map < 3
#w_mask <- nff_map == 3

nf_maks <- nff_map == 4 

nf_mask <- mask(nf_maks, as(aoi,'Spatial'))
nf_maskpoly <- st_as_sf(nf_mask)





nf_map_masked <- mask(nf_map, nf_mask) 

writeRaster(nf_mask, file.path(nf, "nf_filter.tif"), overwrite = TRUE)



# m <- c(1,2, 1)
# rclmat <- matrix(m, ncol=3, byrow=TRUE)
# forest_aoi <- terra::classify(aoi, rclmat, othersNA=TRUE, include.lowest=TRUE)
# 
# m <- c(4, 1)
# rclmat <- matrix(m, ncol=2, byrow=TRUE)
# water_aoi <- terra::classify(aoi, rclmat, othersNA=TRUE, include.lowest=TRUE)
# 
# m <- c(3, 1)
# rclmat <- matrix(m, ncol=2, byrow=TRUE)
# nf_aoi <- terra::classify(aoi, rclmat, othersNA=TRUE, include.lowest=TRUE)







```











  
We are currently testing multiple methods to generate a stage 2 sampling plan 

1) Use entropy layer (as conducted by Colin and Che at Aleza Lake)
2) Generate multiple maps and uncertainty using multiple models (ie XGBoost, ranger, ) and sample in areas of highest uncertainty between maps

## Generate Entropy layer 

```{r generate entropy layer}

entropy <- function(prob_folder)

  prob_dir <-list.dirs(out_dir)
  prob_files <- prob_dir[grep("\\predicted$",  prob_dir)]
    

  # check if more then one BGC is mapped
  bgcs <- gsub(paste0(out_dir,"/"), "", prob_files)
  bgcs <- gsub("/.*","", bgcs) 

  bgcs <- bgcs[4]
  
  if(length(bgcs == 1)) {
    i = 2
    
    bgc <- bgcs[i]
    
    fname <- paste(out_dir, bgc, paste0(bgc,"_entropy.tif"), sep = "/")
    #fname1 <- paste(out_dir, bgc, paste0(bgc,"_entropy1.tif"), sep = "/")
    #fname2 <- paste(out_dir, bgc, paste0(bgc,"_entropy2.tif"), sep = "/")
        
    probabilities <- list.files(prob_files[i], pattern= "\\.tif$", full.name= TRUE)
 #   probabilities <- probabilities[-(grep("response.tif$", probabilities))]
    
   # tprob <- probabilities[1:2]
   #  probabilities <- stack(tprob)
    
    
    probabilities <- stack(probabilities)
    n <- nlayers(probabilities)
    f1 <- function(x){x*log(x+0.000001)}
    
    library(snow)
    beginCluster(4)
    probabilities <- clusterR(probabilities, calc, args=list(fun=f1))
    entropy <- calc(probabilities, fun=sum)
    entropy2 <- -1*entropy/log(n)
    endCluster()
    bc3005 = "+init=epsg:3005"
    entropy <- projectRaster(entropy , crs = bc3005, 
                                 method = "bilinear"#"ngb"
                                 )
    
    writeRaster(entropy, filename= fname, format="GTiff", overwrite=TRUE)
    writeRaster(entropy2, filename= fname2, format="GTiff", overwrite=TRUE)
    }

  
  ## Plot Entropy layer
  my_pal <- rev(brewer.pal(100,"Blues"))
  # plot(entropy, col = my_pal, main = "Entropy / Uncertainty", legend = TRUE, axes = FALSE, box = FALSE)

  tm_shape(entropy) +
    tm_raster(palette = my_pal, 
              title = "", 
              legend.hist = TRUE, 
              breaks = seq(0,1, by = .1)) +
    tm_layout(frame = FALSE, legend.outside = TRUE, legend.hist.width = 1, legend.hist.height = 0.5, main.title = "Entropy")

 # PROJ <- as.character(crs(entropy)) ## sets the crs

  
  
```


 
         

