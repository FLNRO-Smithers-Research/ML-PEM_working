---
title: "Testing hypercube space using different number of slices"
output: html_document


---

```{r setup options, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, cache=FALSE,
                      warning = FALSE, message = FALSE,
                      results = 'show',
                      options(dplyr.summarise.inform = FALSE),
                      eval = TRUE)  ## flag eval = false for quick text edits
```

## Testing iterations of training and testing combinations

For new study areas there is a structure of slices sites (ie 5 sites per slice). This enables a bootstrap approach to accuracy measures which holds one slice out of model build and uses it for accuracy measures. 

This is then repeated for each slice with the results averaged to provide confidence levels. 

We tested the loop per site also but found this also generated very large confidence ranges due to individual 

An aspect of this to test is the impact of holding out consecutive amounts of data. 


1 vs 2
1 vs 2, 3
1 vs 2, 3, 4
1 vs 2, 3, 4, 5

...continue for the rest of the loops 

The accuracy metrics were adjusted so all results included the full set of unique site series for a given bgc. This ensured comparisons were equal across all slices and that we could assess accuracy of map accuracy when additional slices were added. 



**considerations/questions**

- where slice is unbalanced? 
- where not full slice. need to account for weighting  



```{r}
library(data.table)
library(terra)
library(sf)
require(tidyverse)
require(ggpubr)
source(here::here('_functions', 'doc_theme_pem.R'))
source(here::here('_functions', 'compare_hypercubes.R'))
```



###need to split map into BGC portions for comparison to sample data by BGC
```{r prep target info}
map <- rast(c("LocalData/rid_level.tif","LocalData/swi_slope.tif",
              "LocalData/tpi.tif","LocalData/twi.tif","LocalData/valley_depth_2.tif"))

 target_classified <- terra::sapp(map, \(x,...) setValues(x,values(classify(x,10))))
bgc <- rast("LocalData/bgc.tif")
  bgc_classified <- terra::sapp(bgc, \(x,...) setValues(x,values(classify(x,3))))
  
  concat_fn <- function(...){
    data <- list(...)
    out <- data[[1]]
    for(i in 2:length(data)){
      out <- out + data[[i]]*10^(i-1)
    }
    return(out)
  }

   target_id <- lapp(target_classified,concat_fn)

  target_freq <- as.data.table(freq(target_id)) ##target_freq has counts of all bins



  ranges <- minmax(map)

require(factoextra)
  setorder(target_freq,-count)
 target_freq2 <- target_freq %>% filter(count > 400) 
  target_freq2 <- as.data.frame(target_freq2) %>% mutate(bin = as.factor(value)) %>% 
    mutate(bin = fct_reorder(bin, desc(count)))
  ggplot(target_freq2, aes(bin, count))+
    geom_col()
```

```{r}
reduced_vars <- read.csv(file.path(fid$model_inputs0310[2],  "reduced_covariate_list.csv")) %>% pull()

bgc_pts_subzone <- readRDS(file.path(fid$model_inputs0310[2], "model_input_pts.rds"))

  xx <- names(bgc_pts_subzone[1])
  alldat1 = bgc_pts_subzone[[xx]]
  xx <- names(bgc_pts_subzone[2])
  alldat2 = bgc_pts_subzone[[xx]]
  xx <- names(bgc_pts_subzone[3])
  alldat3 = bgc_pts_subzone[[xx]] 
  thesample = rbind(alldat1, alldat2, alldat3)
  thesample <- as.data.table(thesample) %>% filter(position == "Orig")
```

```{r view univariate distributions}
# require(DataExplorer)
#  map2 <- as.data.table(map)
# thesample2 <- as.data.table(thesample) %>% filter(Position == "Orig") %>% dplyr::select(rid_level, swi_slope, tpi, twi, valley_depth_2)
#  plot_histogram(thesample2)
#   plot_histogram(map2)
#   create_report(thesample2)
#   create_report(map2)
#     
#   setorder(target_freq,-count)
#   target_freq <- as.data.frame(target_freq) %>% mutate(bin = as.factor(value))
#   
#   ggplot(target_freq, aes(value, count))+
#     geom_col()
#     

```

```{r builds model iteratively by slice_no, echo = FALSE, eval = FALSE}
# get unique ss for the given variant 

##NEED TO BRING IN TRDAT FROM Balancing script**************************

allcomp <- fread("Localdata/DeceptionSliceCompare.csv")
alldat <- thesample  %>% dplyr::filter(fnf == "forest", position == "Orig") %>% 
    dplyr::select(bgc_cat, slice, mapunit1) %>% 
    mutate_if(is.character, as.factor) %>% mutate_if(is.numeric, as.factor)# %>% filter(bgc == "SBSmc2")
  slices <- unique(alldat$slice) %>% droplevels()
   bgcs <- unique(alldat$bgc_cat) %>% droplevels()
     l = "SBSmc2"
  k=1
    sresults <-
        n_mapunits <- foreach(l=unique(alldat$bgc_cat), .combine='rbind') %:%
        foreach(k = 1:nrow(filter(allcomp, bgc_cat == l)), .combine=rbind) %dopar% {
      allcomp2 <- allcomp %>% filter(as.character(bgc_cat) %in% l) %>% dplyr::select(-slice, -bgc_cat) %>% droplevels()
      train_slice <- allcomp2[k,c(2:5)] %>% droplevels() %>% t() %>% na.omit()
      assess_slice <- allcomp2[k,1] %>% droplevels() %>% t()%>% na.omit()
          
 #k <- 1
  train_slice <- allcomp[k,1:5] %>% t() %>% data.frame
  train_slice <- as.vector(train_slice$.[!is.na(train_slice$.)])
  slice_no = as.vector(allcomp2[k,6])
#  test_no = as.vector(allcomp2[k,7])
  #test_slice <- allcomp[k,1] %>% droplevels()%>% t()  
  subsample <- as.data.table(thesample) %>% filter(slice %in% train_slice)  %>% dplyr::select(rid_level, swi_slope, tpi, twi, valley_depth_2)

result <- compare_hypercubes(target_hypercube = map, sample_hypercube = subsample, bins = 10)
result$slice_no <- slice_no$slice_no
#result$test_no <- unique(all)
x <- unique(allcomp2$bgc_cat)
result$bgc <- unique(allcomp2$bgc_cat)
return(result)
  ### split into train and test based on 5-site slices
}
allresults <- as.data.table(sresults) %>% t() %>% as.data.frame %>% dplyr::rename("missed" = 1, 'missed_ex' = 2, 'num_slices' = 6, 'test_id' = 7) %>% dplyr::select(missed, missed_ex, num_slices, test_id)

fwrite(allresults, "./PEM_standards_manuscripts/outputs/MissedSpacebySlice.csv")
```



```{r compare accuracy of different slice numbers, echo = FALSE, warning = FALSE, message= FALSE}
allresults <- fread("./PEM_standards_manuscripts/outputs/MissedSpacebySlice.csv")#  
allresults2 <- allresults %>% select(-test_id) %>% dplyr::rename("Missed Bin Area" = "missed","Missed Extreme Bin Area" = 'missed_ex') %>% 
  pivot_longer(!num_slices, names_to = "missed_type", values_to = "missed") %>% mutate(num_slices2  = as.factor(num_slices)) 

overall_acc <- ggplot(allresults2, aes(num_slices2, missed)) + 
  geom_boxplot() +
  facet_wrap("missed_type", nrow = 1)+
  geom_hline(yintercept = 10,linetype ="dashed", color = "black", size = 0.5) + 
    geom_hline(yintercept = 5,linetype ="dashed", color = "grey", size = 0.5) + 
  ggtitle(paste0()) + 
  theme(axis.text.x = element_text(angle = 90)) +
  xlab("Number of Slices Sampled") + ylab("Percent of AOI with Unsampled Bins") + 
  ylim(-0.05, 50) +
  theme_pem_facet() + 
  scale_fill_discrete_sequential(palette = "Light Grays")
overall_acc
   
finalise_facet_plot(overall_acc, "./PEM_standards_manuscripts/outputs/missed_bins.png", width_pixels=360,
                          height_pixels=240)
```


   
   
   
   n_mapunits <- foreach(l=unique(sumbyslice$bgc), .combine='rbind') %:%
 
       foreach(k = 1:nrow(filter(allcomp, bgc_cat == l)), .combine=rbind) %dopar% {
      
      allcomp2 <- allcomp %>% filter(as.character(bgc_cat) %in% l) %>% dplyr::select(-slice, -bgc_cat) %>% droplevels()
      max_ss <- mapunits_mapped %>% filter(bgc %in% l)
      
      train_slice <- allcomp2[k,c(2:5)] %>% droplevels() %>% t() %>% na.omit()
      assess_slice <- allcomp2[k,1] %>% droplevels() %>% t()%>% na.omit()
      # training set data
      BGC_train <- sumbyslice %>% filter(bgc %in% l, test_slice %in% train_slice) %>% droplevels()
        #filter(is.na(mapunit2)) %>% filter(!is.na(target)) %>%  ## mapunit2 removed since only pure calls are used in model build
      #BGC <- unique(BGC_train$bgc_cat2) %>% as.character
      #BGC_train <-   BGC_train %>% filter(str_detect(mapunit1, BGC)) ### only looking at site series map classes
      mapunit_no <- unique(BGC_train$mapunit1) %>%  length() %>% as.data.frame %>% rename(mapunit_no = 1)
      
      BGC_test <- sumbyslice %>% filter( test_slice %in% assess_slice, bgc %in% l) %>% droplevels()
      
      mapunit_test <- length(unique(BGC_test$mapunit1)) %>% as.data.frame %>% rename(mapunit_test = 1) 
      
      all <- rbind(BGC_test, BGC_train)
      #all <- rbind(BGC_train)
      all_num <- length(unique(all$mapunit1)) #%>% as.data.frame %>% rename(mapunit_all = 1) 
      
      build_no <- allcomp2[k,]  %>% dplyr::select(slice_no)
      mapunit_count <- cbind(build_no, mapunit_no, mapunit_test, max_ss)
      mapunit_count$bgc <- l
      mapunit_count <- mapunit_count %>% mutate(all_no = all_num)
      mapunit_count
    }
  #}

## Impact of adding more slices

The plots below show the range in spread of accuracy measures when additional slices are added. 
The initial plot shows boxplot results (95% spread of data with the quartiles). 
The second plot shows the **average** and **standard deviation** of all replicates for the number of slices, for examples slice no = 1 is two slices of data (1 for train and 1 for test), Slice no. 4 = 1 test and 3 train. 

SBSmc2 = 75 model runs (5 slices)
ESSFmc = 186 model runs (6 slices)
ESSFmcw = 2 model runs (2 slices)

```{r, echo = FALSE}
overall_acc

```

## ESSFmc. 
 This variant has 6 slices but very imbalanced in transect number per slice. 

```{r, echo = FALSE, messgae = FALSE}
data_all <- read_csv(file.path(paste0(AOI_dir), "results", "num_slice_acc", "ESSFmcacc_results.csv"))[,-1]

bgcs2 <- "ESSFmc"

# check the number of site series per slice
data_check_ss <- as.data.frame(table(data_all$slice))
data_check_no <- as.data.frame(table(data_all$slice_no))
data_check <- as.data.frame(table(data_check_ss$Freq))

acc_sum <- data_all  %>%
   mutate(slice = as.factor(slice)) %>%
    mutate(across(ends_with("overall"), ~.x *100)) %>%
    mutate(across(ends_with("meanacc"), ~.x *100)) %>%
    dplyr::select(slice_no.x, slice, transect_no,
                  aspat_p_overall,  aspat_p_meanacc, 
                  aspat_fp_overall,  aspat_fp_meanacc,
                  spat_p_overall, spat_p_meanacc,
                  spat_pf_overall,  spat_pf_meanacc, 
                  aspat_pa_overall,  aspat_pa_meanacc,
                  aspat_fpa_overall, aspat_fpa_meanacc,
                  spat_pa_overall,  spat_pa_meanacc,
                  spat_fpa_overall, spat_fpa_meanacc ) %>%
  distinct() %>% mutate(slice_no.x = as.factor(slice_no.x))

acc_sum_long <- acc_sum %>%
    pivot_longer(cols = where(is.numeric), names_to = "accuracy_type", values_to = "value") %>%
  filter(accuracy_type != "transect_no")

# add the grouping for number of slices (and calculate average)
bsRes2_all <- acc_sum_long %>% mutate(accuracy_type = as.factor(accuracy_type))

# perform T-test
zz <- compare_means(value ~ slice_no.x, bsRes2_all, method = "t.test", group.by = "accuracy_type", p.adjust.method = "holm") 

bsRes2_detail <- format_accuracy_measures(bsRes2_all)

overall_acc1 <- ggplot(aes(y = value, x = accuracy_type_label, fill = as.factor(slice_no.x)),data = bsRes2_detail) + 
   geom_boxplot() +
  facet_wrap(~type_f, nrow = 2)+
  geom_hline(yintercept = 65,linetype ="dashed", color = "black", size = 0.8) +  
  ggtitle(paste0("Accuracy measure with increasing slices: ", bgcs2)) + 
  theme(axis.text.x = element_text(angle = 90)) +
  xlab("iteration") + ylab("Accuracy") + 
  ylim(-0.05, 100) +
  theme_pem_facet() + 
  scale_fill_discrete_sequential(palette = "Light Grays")
```

```{r, echo = FALSE}
overall_acc1

```

## ESSFmcw

```{r - essfmcw, echo = FALSE}
###readin saved acc output csv s and combine
data_all <- read_csv(file.path(paste0(AOI_dir), "results", "num_slice_acc", "ESSFmcwacc_results.csv"))[,-1]

bgcs2 <- "ESSFmcw"

# check the number of site series per slice
data_check_ss <- as.data.frame(table(data_all$slice))
data_check_no <- as.data.frame(table(data_all$slice_no))
data_check <- as.data.frame(table(data_check_ss$Freq))

acc_sum <- data_all  %>%
   mutate(slice = as.factor(slice)) %>%
    mutate(across(ends_with("overall"), ~.x *100)) %>%
    mutate(across(ends_with("meanacc"), ~.x *100)) %>%
    dplyr::select(slice_no, slice, transect_no,
                  aspat_p_overall,  aspat_p_meanacc, 
                  aspat_fp_overall,  aspat_fp_meanacc,
                  spat_p_overall, spat_p_meanacc,
                  spat_pf_overall,  spat_pf_meanacc, 
                  aspat_pa_overall,  aspat_pa_meanacc,
                  aspat_fpa_overall, aspat_fpa_meanacc,
                  spat_pa_overall,  spat_pa_meanacc,
                  spat_fpa_overall, spat_fpa_meanacc ) %>%
  distinct() %>% mutate(slice_no = as.factor(slice_no))

acc_sum_long <- acc_sum %>%
    pivot_longer(cols = where(is.numeric), names_to = "accuracy_type", values_to = "value") %>%
  filter(accuracy_type != "transect_no")

# add the grouping for number of slices (and calculate average)
bsRes2_all <- acc_sum_long %>% mutate(accuracy_type = as.factor(accuracy_type))

# perform T-test
#zz <- compare_means(value ~ slice_no, bsRes2_all, method = "t.test", group.by = "accuracy_type", #p.adjust.method = "holm") 

bsRes2_detail <- format_accuracy_measures(bsRes2_all)

overall_acc2 <- ggplot(aes(y = value, x = accuracy_type_label, fill = as.factor(slice_no)),data = bsRes2_detail) + 
   geom_boxplot() +
  facet_wrap(~type_f, nrow = 2)+
  geom_hline(yintercept = 65,linetype ="dashed", color = "black", size = 0.8) +  
  ggtitle(paste0("Accuracy measure with increasing slices: ", bgcs2)) + 
  theme(axis.text.x = element_text(angle = 90)) +
  xlab("iteration") + ylab("Accuracy") + 
  ylim(-0.05, 100) +
  theme_pem_facet() + 
  scale_fill_discrete_sequential(palette = "Light Grays")

```


```{r}
overall_acc2
```


**Take aways**
- overall accuracy improves with adding more data
- minimal change in the error bars (potentially an issue?)

```{r, echo = FALSE, eval = FALSE}
### Number of site series sampled by number of slices used in build
bgcoi_string = "sbsmc"

allcomp <- read_csv(file.path(AOI_dir, "results", "num_slice_acc", "SBSmc2matrix.csv"))[,-1]

# trDat2 <- tpts %>%
#   filter(str_detect(tid, bgcoi_string)) %>% # need to adjust this
#   mutate(slice = as.factor(slice)) %>%
#   dplyr::select(-bgc_cat)
# 

n_mapunits <- foreach(k = 1:nrow(allcomp), .combine=rbind) %do% {
#n_mapunits <- foreach(k = 1:5, .combine=rbind) %do% {  
#k = 1
   
   train_slice <- allcomp[k,2:(length(allcomp)-2)] %>% droplevels() %>% t()
   test_slice <- allcomp[k,1] %>% droplevels() %>% t()
  
   # training set
  BGC_train <- trDat %>% 
    dplyr::filter(slice %in% train_slice) %>%
    filter(is.na(target2)) %>% 
    filter(!is.na(target))
  
  mapunit_no <- length(unique(BGC_train$target)) %>% as.data.frame %>% dplyr::rename(mapunit_no = 1)
 
  BGC_test <- trDat2 %>% dplyr::filter(slice %in% test_slice) #%>%    
 # filter(is.na(target2)) %>% filter(!is.na(target))
  
  mapunit_test <- length(unique(BGC_test$target)) %>% as.data.frame %>% dplyr::rename(mapunit_test = 1) 

  all <- rbind(BGC_test, BGC_train)
  all_no <- length(unique(all$target)) %>% as.data.frame %>% dplyr::rename(mapunit_all = 1) 
  
  build_no <- allcomp[k,]  %>% dplyr::select(slice_no) 
  mapunit_count <- cbind(build_no, mapunit_no, mapunit_test, all_no)
  mapunit_count <- mapunit_count %>%
    mutate(slice = paste0(k))
}


overall_acc1 <- ggplot(aes(y = mapunit_all, x = slice_no),data = n_mapunits) + 
  ggtitle(paste0(bgcoi_string)) +   
  geom_jitter( width = 0, height = .2) +
   xlab("Number of Slices in Analysis Set") + ylab("Map units in Sample Set")+
  scale_y_continuous(expand = c(0, 0), limits = c(0, 10), breaks= pretty_breaks()) +
  theme_pem()
overall_acc1

ggsave("../PEM_standards_manuscripts/ESSFmc_UnitsperAnalysisSetSize.pdf")

```



